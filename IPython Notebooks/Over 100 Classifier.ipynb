{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from helpers import *\n",
    "from convnet_experiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'netdata'\n",
    "train = np.load(os.path.join(DATA_DIR, 'standardized_train.npy'))\n",
    "train_labels = np.load(os.path.join(DATA_DIR, 'labels_train.npy'))\n",
    "test = np.load(os.path.join(DATA_DIR, 'standardized_test.npy'))\n",
    "test_labels = np.load(os.path.join(DATA_DIR, 'labels_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN_NAME = 'CRPS-MODEL-3.0'\n",
    "DATA_DIR = 'netdata'\n",
    "ITERS = 100000\n",
    "START_ITER = 0\n",
    "MODEL_LOAD_PATH = None\n",
    "PIC_WIDTH = 32\n",
    "### Architectural Hyperparameters\n",
    "DEPTH_1 = 8         # The output depth of the first convolutional layer\n",
    "DEPTH_2 = 16         # The output depth of the second convolutional layer\n",
    "DEPTH_3 = 20         # The output depth of the second convolutional layer\n",
    "DEPTH_4 = 24        # The output depth of the second convolutional layer\n",
    "DEPTH_5 = 30        # The output depth of the second convolutional layer\n",
    "DEPTH_6 = 40        # The output depth of the second convolutional layer\n",
    "\n",
    "NUM_OUTPUTS = 25    # Number of output classes in the softmax layer\n",
    "KERNEL_X = 3         # The width of the convolution kernel (using same for 1st and 2nd layers)\n",
    "KERNEL_Y = 3         # The height of the convolution kernel (using same for 1st and 2nd layers)\n",
    "mu = 0.0001\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "REGULARIZE_BIAS = False\n",
    "\n",
    "NUM_INPUTS = 9  \n",
    "NUM_REPS = 144\n",
    "\n",
    "TRAIN_LABEL_NOISE_STD = 2.\n",
    "TRAIN_LABEL_SMOOTHING_STD = 0.\n",
    "DATA_AUGMENTATION = True\n",
    "DIASTOLE = False\n",
    "\n",
    "###########################################\n",
    "NUM_INPUTS = 9       # Number of input channels\n",
    "NUM_OUTPUTS = 2\n",
    "NUM_REPS = 144\n",
    "TRAIN_LABEL_NOISE_STD = 0.0001\n",
    "TRAIN_LABEL_SMOOTHING_STD = 0.\n",
    "LEARNING_RATE = 1e-3\n",
    "mu = 0.05\n",
    "DATA_AUGMENTATION = True\n",
    "RUN_NAME = 'TWO-CLASS-EXP'\n",
    "DEPTH_1 = 4         # The output depth of the first convolutional layer\n",
    "DEPTH_2 = 4         # The output depth of the second convolutional layer\n",
    "DEPTH_3 = 4         # The output depth of the second convolutional layer\n",
    "DEPTH_4 = 2        # The output depth of the second convolutional layer\n",
    "DEPTH_5 = 2        # The output depth of the second convolutional layer\n",
    "DEPTH_6 = 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    ####################################### INPUT/OUTPUT PLACEHOLDERS ##############################################\n",
    "    x = tf.placeholder(tf.float32, shape=[None, PIC_WIDTH, PIC_WIDTH, NUM_INPUTS]) #Placeholder for the input images\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, NUM_OUTPUTS]) #Placeholder for the label cdfs\n",
    "    ####################################### FIRST CONVOLUTIONAL LAYER ##############################################\n",
    "    # The weight tensor has dimensions [kernel_size_x, kernel_size_y, num_input_channels, num_output_channels]\n",
    "    W_conv1 = weight_variable([KERNEL_X, KERNEL_Y, NUM_INPUTS, DEPTH_1])\n",
    "    b_conv1 = bias_variable([DEPTH_1])\n",
    "    #Take the input image, reshape it to a 4D tensor with dimensions: [_, image_width, image_height, num_channels]\n",
    "    #x_image = tf.reshape(x, [-1,32,32,3])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    ####################################### SECOND CONVOLUTIONAL LAYER ##############################################\n",
    "    W_conv2 = weight_variable([KERNEL_X, KERNEL_Y, DEPTH_1, DEPTH_2])\n",
    "    b_conv2 = bias_variable([DEPTH_2])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    ####################################### THIRD CONVOLUTIONAL LAYER ##############################################\n",
    "    W_conv3 = weight_variable([KERNEL_X, KERNEL_Y, DEPTH_2, DEPTH_3])\n",
    "    b_conv3 = bias_variable([DEPTH_3])\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    h_pool3 = max_pool_2x2(h_conv3)\n",
    "    ####################################### FOURTH CONVOLUTIONAL LAYER ##############################################\n",
    "    W_conv4 = weight_variable([KERNEL_X, KERNEL_Y, DEPTH_3, DEPTH_4])\n",
    "    b_conv4 = bias_variable([DEPTH_4])\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\n",
    "    h_pool4 = max_pool_2x2(h_conv4)\n",
    "    # ####################################### FIFTH CONVOLUTIONAL LAYER ##############################################\n",
    "    #This layer uses a 1x1 convolution\n",
    "    W_conv5 = weight_variable([1, 1, DEPTH_4, DEPTH_5])\n",
    "    b_conv5 = bias_variable([DEPTH_5])\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_pool4, W_conv5) + b_conv5)\n",
    "    h_pool5 = tf.nn.avg_pool(h_conv5,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    h_pool5_flat = tf.reshape(h_pool5, [-1, DEPTH_5])\n",
    "    ############################################### DROPOUT ##########################################################\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_pool5_flat, keep_prob)\n",
    "    ############################################# SOFTMAX OUTPUT LAYER ###############################################\n",
    "    W_fc2 = weight_variable([DEPTH_5, NUM_OUTPUTS])\n",
    "    b_fc2 = bias_variable([NUM_OUTPUTS])\n",
    "\n",
    "    y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "    ##################################### SETTING UP THE OPTIMISATION PROBLEM #####################################\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y+1e-12))\n",
    "    loss = cross_entropy + mu*(tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(W_conv2)\n",
    "                                + tf.nn.l2_loss(W_conv3) + tf.nn.l2_loss(W_conv4)\n",
    "                                + tf.nn.l2_loss(W_conv5) + tf.nn.l2_loss(W_fc2))\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    xentrop_summ = tf.scalar_summary(\"Cross Entropy\", loss)\n",
    "    accuracy_summ = tf.scalar_summary(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the relevant data through the classifier, in this case I'm running the 200 test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient  0\n",
      "Patient  40\n",
      "Patient  80\n",
      "Patient  120\n",
      "Patient  160\n"
     ]
    }
   ],
   "source": [
    "MODEL_LOAD_PATH = 'TWO-CLASS-EXP/model-13000'\n",
    "predictions = []\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, MODEL_LOAD_PATH)\n",
    "    for i in range(200):\n",
    "        if i%40 == 0:\n",
    "            print 'Patient ', i\n",
    "        Xt,yt = batch(test[:,i:i+1], [])\n",
    "        pred = session.run([y], feed_dict={x: Xt, keep_prob: 1.0})[0]\n",
    "        ### Average over all 144 predictions\n",
    "        pred = np.mean(pred, axis=0)\n",
    "        predictions.append(pred)\n",
    "    predictions = np.array(predictions)\n",
    "class_pred = predictions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x124a2c390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHllJREFUeJzt3XuQXOV55/Hv0xoGRiAQg4QgSA5kbC9gY2jhgBxlrdlL\na4RrC69Gu77ETs3iFCIVG7Iw4AnWbixgWELCYMI6CSjrIK2vW7VEKbnW7kE4jHah7LC2JVlcZEMc\nUtxtGSdLNrMeyfPsH+fMTE/fL+dM9zn9+1R1qfv06bffdwae887zXo65OyIikj6ZdldARETioQAv\nIpJSCvAiIimlAC8iklIK8CIiKaUALyKSUj1L9UVmpvmYIiJNcHdr5nNL2oN399Q+Pv3pT7e9Dmqf\n2qb2pe/RCqVoRERSSgFeRCSlFOAjMjg42O4qxCrN7Utz20Dt62bWao6n7i8y86X6LhGRtDAzPAmD\nrCIisnQU4EVEUkoBXkQkpRTgRURSSgFeRCSlFOBFRFJKAV5EJKUU4EVEUkoBXkQkpRTgRURSSgFe\nRCSlFOBFRFJKAV5EJKUU4EVEUqpmgDezPzOz183sSJVz7jez58zssJllo62iiIg0o54e/EPAlkpv\nmtn7gLe6+9uA7cCfRFQ3kYomJyfZvHkb69cPsn79r87/u3nzNu688042b97G5s3bmJycbHdV583V\nuVa96jmv3rLSqJvb3rA6b/p6PnCkwnsPAB8seH0UWFPmPJfulc/nPZcb9lxu2PP5fMVjhcbHx72/\nf8BPO+1cHxi4zLPZjT4wcJmvWPEWN1vhMOqw22Glw7bw34sdTg+P73azlT4+Pl5S9sjIiPf0nO09\nPWd7Npv1/v4B7+8fKDm3Vh1rtTmb3eT9/QM+MHCx9/aunq9XX9+asuXl83nv61tT9bx6zilXbrPt\n6CTNtD3pwtjZ3A276zqpeoD/KvArBa8fBS4vc17MPwbpVOX+pxwfH6/6P+r4+HgYqEcdVoX/njl/\nfnBspUM+fH1WGOTnzvHwsdvhTM/n8/NB7txzz190EVj4nuD5XJBfXO9Rz2TO8mx2U10BJZ/PLwro\n0F9Sr1xuuORzudxwzfPqOafWzz+pQbHRtqdBKwG+J6I/BIpvJ1X23nw7d+6cfz44OKh7KXaYyclJ\nJiZ2ATA6up2hoaFIyp2Y2MX09N3ACADT03DvvXeUHJuY2DX/nffe+xBwP7APuIcgU/iZ+fMDDwC7\ngKuB1cA3gAvL1MD4+Mdv4ZVXfhR+55Nh2YVlzX1PULcdO3YU1PscYIzZ2QkOHoStW0fYu3dP1Z/P\nxMQuZmb+oOA7HqjjJxWPcj//wp+1dJapqSmmpqYiKSuKAP8ysK7g9drwWInCAC+dZXJykq1bR8JA\nAI8/XjuIFX9+YmIXx479BDjBqlVrql4kjh8/XmfNXicIjj+s8P4rwBhBgL+PIBgXBu4x4Br+9m8/\nz4kTvx++d0ed3z1nF9BqgNwI/Pb8q76+MUZH95ScNTq6nccfH2F6uvJ59ZyTVt3Q9uLO72233dZ8\nYfV086meonkf8LXw+QbgWxXOi/kPGWlFK3/6FqcA5lIqc6mAIF2x0mGDwwbv6TnDe3pODc8LPtPb\nu3pRbn5g4GKH5QWpjdGitMqq8P0Li9I3HqZtNjgMzKdwVqxYV/D+uNeTollIE21o+GeTz+e9p+es\novqe7AMDl9XMg9eTL28kp56mFI17esYT6kWcOXjgywTdpBngReBjwHXAdQXnfBZ4HjgMrK9QzlL8\nLKRJ9Qb4cv9zlfssDM+XUZyPNlsZBtR8eN4Gz2Y3zpe/EIwGisoddVjjsNbNVvjIyIjncsOezW7y\nU07pX3TBKAzavb2rS3L+cIrDaoezHd7iPT1nlwyyBu0addjohfn/egNkNrsxvDgMz19o2pUv7rag\nmCaxBvioHgrwna2V2Ru1Anz59zeUvZgsPrf0c/39A2WDVOlfCad6Nrup7KydbHZTeG71gL24LsFf\nBf39A3UHyG4cEJToKcBLJGr18ioFrGopmrmpjkHgzc9/LpNZSF9kMmfO95xLg+qqmoG43vo3em6r\nqY20pUakPVoJ8BZ8Pn5m5kv1XRKPzZu3sX//1SwMYu4hl9vHI488XHaQddOm9dx++z3MzMzNbHkG\nyJHJTLFmzVm89tqruJ8H9JDJvMrtt9/Iu9/97oLB3iOY7eK0087krW+9gLvuurXiwGaUM4AKy9q0\naT0HDny36XLjmpkk3cPMcPfimYr1afbK0OgD9eA7Vr0930Z7pEEOelVRz/60ojz56kU9+blB2Wx2\no2cy9eW9o+wpq9ctnQalaKRZjQa0RtIgQWqmOPe+tuB15dkpjeSvo8x1K28unaaVAB/VQidJqEYX\nwQwNDdWdZvjFX1zLG28UH13ZfGW7nNI90igF+C5UGCiOHXs9tu/Zti3HwYM3FBy5ATgBzC1MeYpK\ni38aWdAS5eKXpVxI00jAbnUhmnSpZrv+jT5QiqYjFKdkentX1zVlsBkL88iHw8domINf67DWe3pO\n9fHx8Yopn6hnxdRrKeaMN5oaU+qoe6EcvNSrXKCYmy8edUAr/a7RcJFT6erVpGr2YtBowFaA716t\nBHilaIRVq87ikUcejrzc4nRHJrOb2dn7mMv3z8wke9OrpUybdMMeLBKDZq8MjT5QD74jxDkNsNae\n79nsprp7oUlYWh/l/j3dtKe7NAalaKQRcQSKKG9UsXDeqMMGz2TOKnvTjnZrNW2igC31UICXtmtl\ns7LyZc1tLLZ4EVQn0aIoWQqtBHjl4GVJ1TOPPtju4BUK92Cfne28fP3Q0BB79+4pmOqoaYvSWRTg\nJRJRDQJOTk7y9NOHqe9+8O3XyMIvkaWmAC9V1Xunpqh6s8Gt7u4DXgJunD+uWSMijdNuklJR8TRA\nuBkYoa/vC3VPB2x0ef3iHSsngZ309/+YL33pj9RTlq6k3SQlFrVu5FFLs1MBNXApsoAWBlmTkeiU\nRFq8kVnwl8Bcb76SuVRPLrePXG5fUwuHJicn2bx5G5s3b2NycrL5BogknHLwUlHxwOlCiibefHgr\nA5dJ3JRLu0RKbJrt+jf6QCmaRCq8j2k2u7GhRTntSLckbc8WpaSkFjQPXuLSSm+62Zk13dSjbXQ/\nfpFGKMBLrOq5QBTfA/XOO/9z0ykWbcolskDTJKWtinPmmcwos7MTlLuxdyNlJuUvgOL29/WNdfyY\ngSytVqZJKsBLWy2e9w7wHuA3aSXAJ02SLkiy9FoJ8ErRSIfZSCZzI7OzwatyKZa0BURtdyBxUQ9e\n2qpcimLHjus5cOC7QGkAV0pDuo1SNJJojfTIS1M66U/hSHdTikYSTSkKkXhoqwLpSJW2Gxgd3U5f\n3xiwB9gT5ui3t62eIp1MAV5KxLGXSyNlzuXZ9++/mv37r2br1pH5zwwNDbFjx/X0999Bf/8d7Nhx\nvXr/IpU0uwS20QfaqiAR4lg632iZ1bYb0NJ+6TZoqwKJShxL56MsU0v7ReqnAC8dR9sNiESk2a5/\now+UokmETkjRzH0mlxsu2b1SKRrpNrSQotE8eCkRx0rRKMssV1baVreKzNFCJ+lqWt0qaaYAL11N\nq1slzVoJ8JoHLyKSUgrwkgjVFkppdatIeUrRSMerJ8euQVZJK+XgJdWUY5duFmsO3sy2mNlRM3vO\nzMbKvL/KzPJmdsjMnjKzf9dMRUREJFpVV7Ka2TLgs8C/BF4G/reZ7XP3ZwtO+wRw0N1vNbNVwPfN\n7AvufiK2WktX0cpWkebU6sFfATzv7i+4+3HgK8D7i855FTg9fH468BMFd4nS0NAQe/cGaZlcbp/m\nuIvUqdZeNOcBLxa8fgm4suicPwX+0sxeAVYAH4iuetKtyg2aKqiLNKZWgK9nVPRTwCF3HzSzAWC/\nmV3q7m8Wn7hz587554ODgwwODjZQVekWxbNmHn98RL126RpTU1NMTU1FUlbVWTRmtgHY6e5bwte3\nArPufnfBOV8D7nT3J8LX3wDG3P3bRWVpFo3URbNmRBbEOYvm28DbzOx8M+sFPgjsKzrnKMEgLGa2\nBvgnwA+bqYyIiESnaoAPB0s/AUwCzwD/zd2fNbPrzOy68LT/BLzbzA4DjwKfdPc34qy0JFOl1ajF\nx7UyVSQaWugkS6LSalSg4nGtTBXRSlZJgEp5dUD5dpEqtJukiIiU0D1ZZUlUW42qVaoi8VCKRpZM\npR0ftROkSGXKwYuIpJRy8CIiUkIBXkQkpRTgpSXVbqUnIu2lHLw0rZ5b6YlIazTIKm2hTcFE4qdB\nVhERKaGFTtI03UpPpLMpRSMt0SIlkXgpBy8iklLKwYuISAkFeBGRlFKAl5q0mEkkmZSDl6q0mEmk\nvTTIKrHRYiaR9tIgq4iIlNBCJ6lKi5lEkkspGqlJi5lE2kc5eOlqugBJminAS9fSLB9JOwV46Vqa\n5SNpp1k0IiJSQrNoJNE0y0ekMvXgu1Rath8YGhpi794gLZPL7ZvPv6elfSKtUA6+C6V9YDLt7ZPu\nokFWaUjaBybT3j7pLhpkFRGREhpk7UJpH5hMe/tE6qUUTQrVs7Iz7as/094+6R7Kwcs8DTCKpIsC\nvMzTAKNIumiQVURESmiQNWU0wCgic9SDXwJLuaqy0srORkVdZ60sFWkDd1+SR/BV3Sefz3tf3xqH\n3Q67va9vjefz+XZXq6qo65zEn4FIpwhjZ1NxV4OsMUvioGfUdU7iz0CkU8Q6yGpmW8zsqJk9Z2Zj\nFc4ZNLODZvaUmU01UxEREYlYte49sAx4HjgfOAk4BFxUdM5K4Glgbfh6VYWyYv5DpjMlMT3RLSma\nfD7vudyw53LDHVEfkXKIK0VjZu8BPu3uW8LXvxNG6t8rOOe3gHPc/XerXUi6NUUDyVxVGXWdO+1n\noAVhkhSxLXQys38DDLn7teHrjwJXuvv1Bed8hqB3/w5gBfCH7v75MmV1bYBvp04LrJ1C4wKSFK0E\n+Frz4OuJyCcB64F/ASwHvmlm33L355qpkESnuJf6+OMj6qWKdJFaAf5lYF3B63XAS0XnvAgcc/dp\nYNrM/idwKVAS4Hfu3Dn/fHBwkMHBwcZrLHWbmNgVBveglzo9HRxrNsCn6a8BLQiTTjU1NcXU1FQ0\nhVVL0BNcAP6aYJC1l/KDrBcCjxIMyC4HjgAXlykrjvEHqSKXGw4HNj187PZcbripsjp1oLQVGmSV\nJCDOefBmdhVwXxjAP+fud5nZdWHEfjA852bgGmAW+FN3v79MOV7ruyRaUQ4kKmct0h5x5uBx968D\nXy869mDR63uAe5qpgMRnbtuChbSK8u8i3UQrWaUumlYo0h7aD17q1spAaZoGWUWSQgFe6qJeuEjy\nKMBLXTRQKpI8uqOTiIiU0B2duogW94h0F/XgO8RS3PGo3N2eAN1pSSStml0h1egDrWStqF2rROv5\n3nKrPbUCVGTp0MJKVgX4DhDllgJRfm+5C8D4+HjHb1mgC5CkSSsBXjl4qajcZmX33ntHpBuYRU07\naIosUIDvAO0a/EzjoGvUO2iKJJkGWTtAucHPpQhItb53dHQ7fX1jwB5gD319Y9x00zUlx0ZHt7dU\nj6UYYBbpSs3mdhp9oBx8IsU9yNot938VaRZxbhccFa1klXLiWF2rPXMkTWLdLlgkaYaGhhTURVCA\nlzZL40CvSKdQikbaTikVkcq0m6R0NV0gJM0U4KVraY97STttF9xFNGd8scULm4JAP9ebF+l2GmRN\nEC3DF5FGKMAniJbhl9IsHJHKFOAl0ea2W1gYZNVfNCJzNMiaIBpQFOk+mkXTRTQlUKS7KMBL21W6\n8OiCJNIaBXhpq0qpI0ApJZEWKcBLW1XaERKIfKdIkW6jhU4iIlJC0ySlZdXmomuOukj7KEUjJZoZ\nGNUgq0g8lIOXyGiuvUhnUYCXyMRxCz0RaZ4GWSU1infL1O6ZIs3TIKss0s7Nu4rTQwcOfAg4iZmZ\nPwC0e6ZIo5SikRLtGhgtTQ+9B/hNlC6SbtZKikY9eCkxNDSkXrJICijAd4kkTFcsTg/19h4FbmFm\nJnitefQijVGKpgskaepj8YUI6PgLk0icNE1SgMq9dE19FEku5eCl4fu1Hjv2k6Wsnoi0Qc158Ga2\nxcyOmtlzZjZW5bxfNrMTZjYcbRWlHrfeegfT0xcA+4BzmJ6+e1Fvvrf3FmBP+LiZp58+rHnlIilX\nNcCb2TLgs8AW4GLgw2Z2UYXz7gbyQFN/SkjzJicnOXz4GYIphXOpmCPz7w8NDfGOd7wdeIDgAvAF\nZmbum78ANPpdWngkkgy1evBXAM+7+wvufhz4CvD+MuddD/x34McR10/qMDGxi9nZzwDnEATwCzDb\nNT9ICbBq1RqCC8DDQHMDlXNpoP37r2b//qvZunUk8iCvC4hIdGrl4M8DXix4/RJwZeEJZnYeQdD/\n58AvAxpJbYsjwBjBH1IA/37Ru1GsUJ2Y2BXm+IPB2unp4FhUM1saHUcQkepqBfh6gvV9wO+4u5uZ\nUSVFs3Pnzvnng4ODDA4O1lG81DI6up1vfOMjzM5OMBd83RcH36GhIfbu3VOQl++8wBn3BUQkCaam\nppiamoqkrFoB/mVgXcHrdQS9+EKXA18JYjurgKvM7Li77ysurDDAS3SGhoa49NJ3cvBg7fNaCZbt\n3KdGpFsUd35vu+225gtz94oPggvAXwPnA73AIeCiKuc/BAxXeM8lPvl83vv61jjsdtjtfX1rPJ/P\nx/I9udyw53LDkZe/VG0QSZIwdlaN1ZUeNRc6mdlVBGmYZcDn3P0uM7sujNgPFp37EPBVd//zMuV4\nre+S1kS5HUGjZUX13UnYUkFkKWklq0Sq0a0NkrQVgkjSKMB3uSh6vYVlHDv2OgcPXku9WxtoKwSR\n+Girgi4WxdTC4jIymRspXCglIsmkAJ9wUUwtLC5jdhYymVFmZy8Bas+W0ewakc6kAC9lXXrpO1m1\nKpjpWmvOfBLm2HcCDSDLkmt2+k2jDzRNMhZRTC3U9MT46WcszSLOaZJR0SBrfKIeZG1n77JT6hE1\nDURLszTI2uWaWaFaLpC2e+669qIRiVizXf9GHyhF0zGiTBdEWVYuNxyW4+Fjt+dyw02VFbVWV/Aq\nRSPNooUUjQJ8F4oykMZdVn//QCzbIjQiquAc5zYPkl6tBHilaBIkrfnpOcXTLeEG3njjWvbvv6St\n6ZqodrlsdbM3kYY1e2Vo9IF68CUa6dHV24usp8xOTdEU1r+/f8BhtCPSNZ2cOpL0Qyma5Gk0MNYT\nZBopcy6QZrMbPZvd1FTaIIoyKumkoKr8ubSTAnwCNRrA6jm/0TJbCVxxB71OC6rKn0u7tBLglYNP\niDi2A6iWW66V74/77kudtjpW+XNJIgX4NikO2JnMjRw7djGTk5NlA0k9AS+qi0C5+eg7dlzPgQPf\nnf+epaCgKtKiZrv+jT7okhRNowOn2ewmz2TOCgcUS1MRjaYGohi4LU31jHomc+ai88bHxzsqhSKS\nVigH3xmayRtXy5vHlYcuvAiMj4+XXBBK67ShbB2VlxaJXysBXimaCEWdl44jz12afim9+1Jp+ug5\nZmdLy1IKRaSzZdpdgW43Orqdvr4xYA+wJ8ybV85xf+c7h5mcnGz6+4KLxkeBfcA+pqc/Op/XnzOX\n78/l9pHL7eP2229sqI4i0iGa7fo3+kApmqqfK5fqKC4PVjmMtpSqyWY3huUslJnNbqxaj1rviUh8\nUA6+c0QdCPP5fLiqc4NDvuVFP9nsppJ8eja7ycfHx0sGUlutvy4KIq1TgE+5WgOxjQTRxWXlHTb4\nihVvcbMzK35HMzptoZJIUrUS4DXI2mb1bCBWugnXb/Gd76zm9NPfwptv/gT4YwAee+wj7Nx54/x8\n9U2b1i+auz40NMTo6HYOHPgQMzP3AK8A1/Dmm5cAN0XarsUDxJNMT1/Ar/3ax/nSl/5IA7MiS6XZ\nK0OjD7q0B1+uhz0+Pu4rVqzzZctWO5zi8M4wBXOy9/ae7cuWneU9PWc4nOxwpkO/w0kOpzmsDY/N\n5dDPdNjoMBzOpT8jfJwWPlaGr1d6X9+5PjIy4r29qws+vybsyY+G5wbHzVa2tCXuwmZh+fA71JMX\naQZK0XSmcmmKkZERh9PDY6MVnu8OA3/h69PDgD8XhBdSKQvz1FcVDKD2hwF+tGhQ9XQv3qUxuDjs\ndjg1LGuD9/Sc0fK9XYPvujDS1I9It2klwCtFE6Ny89i/+MVPAveHx7ZVeA7wH4DxgtcAN1f4pl8o\nOO8/Fjx/APgb4J6ich4o+vwrYdnrgG8CcOLEnobn3Be3t3qdRSRuCvCJdHPR8y8UvP6lOj7/fYI5\n7QA3AhcTBOUnIqndYucAY/OvMpkbGR39cgzfIyLFFOBjVG7zrw984Cr27LkhPOMCoNxzgGNFr28A\nfhY+X0bQC/8H4B+B1wgC9g3AteHzm4AZYCOLLwg3MDKyle997yEOH36K2dmPAZfQ23sLcJyZmT3z\ndW10o7Li9i6U+RvAA2Qyz3H77aMaZBVZIhakeJbgi8x8qb6rk5SbJXPnnXdy990PMj39M1avXs7y\n5Sv56U/f5OSTj/N3f3eCmZmfYXaCEyf+H7AcMOD/MjDwdq655oM8/PDXOXLkWU6cmAWmgeX09p7E\ne9/7Lp544immp6eBnwPQ03MymYzz858by5cvZ2zsOnbs2FG2bkDLtwSMo0yRbmZmuLs19VkFeBGR\nztVKgNdeNCIiKaUALyKSUgrwIiIppQAvIpJSCvAiIimlAC8iklIK8CIiKaUALyKSUgrwIiIppQAv\nIpJSdQV4M9tiZkfN7DkzGyvz/kfM7LCZfc/MnjCzd0VfVRERaUTNAG9my4DPAlsI9pX9sJldVHTa\nD4H3uvu7gDuAXVFXtNNNTU21uwqxSnP70tw2UPu6WT09+CuA5939BXc/DnwFeH/hCe7+TXf/+/Dl\nXwFro61m50v7f2Rpbl+a2wZqXzerJ8CfB7xY8Pql8FglvwF8rZVKiYhI6+q54Ufde/ya2T8DPkZw\nlwkREWmjmvvBm9kGYKe7bwlf3wrMuvvdRee9C/hzYIu7P1+mHG0GLyLShGb3g6+nB/9t4G1mdj7B\n3Zk/CHy48AQzewtBcP9oueDeSgVFRKQ5NQO8u58ws08AkwQ3A/2cuz9rZteF7z8I/C5wJvAnZgZw\n3N2viK/aIiJSy5Ldsk9ERJZW5CtZzezfmtnTZvZzM1tf9N6t4WKpo2a2ueD45WZ2JHzvD6OuU5xq\nLQJLAjP7MzN73cyOFBzrN7P9ZvYDM3vEzFYWvFf299ipzGydmT0W/nf5lJndEB5PfBvN7BQz+ysz\nO2Rmz5jZXeHxxLetkJktM7ODZvbV8HVq2mdmL4SLRA+a2ZPhsWja5+6RPoALgbcDjwHrC45fDBwC\nTgLOB55n4S+IJ4ErwudfIxiojbxuMbR1WdiO88N2HQIuane9mmjHPwWywJGCY78PfDJ8Pgb8XpXf\nY6bdbajRvnOAy8LnpwHfBy5KSxuB5eG/PcC3gF9NS9sK2ngT8EVgXwr/+/wboL/oWCTti7wH7+5H\n3f0HZd56P/Bldz/u7i+EFbvSzM4FVrj7k+F5/xX411HXKyY1F4Elgbv/L+CnRYevBvaEz/ew8Dsp\n93vs6PEWd3/N3Q+Fz/8BeJZgLUcq2uju/xg+7SXodPyUlLQNwMzWAu8D/gswN1kjNe0LFU9CiaR9\nS7nZ2C8QLJKaM7dgqvj4y1RfSNVJGl0EliRr3P318PnrwJrweaXfYyKEs8GyBCuuU9FGM8uY2SGC\nNjzm7k+TkraFPgPcAswWHEtT+xx41My+bWbXhsciaV890yRLmNl+gj97i33K3b/aTJkJ1RUj1O7u\nNdYxJOLnYGanAQ8Dv+3ub4YzvoBkt9HdZ4HLzOwMYDJccFj4fmLbZmb/CviRux80s8Fy5yS5faGN\n7v6qma0G9pvZ0cI3W2lfUwHe3XNNfOxlYF3B67UEV5+XWbx3zdrwWBIUt2kdi6+uSfa6mZ3j7q+F\nabQfhcfL/R47/vdlZicRBPfPu/tfhIdT1UZ3/3sz+x/A5aSnbb8CXG1m7wNOAU43s8+Tnvbh7q+G\n//7YzPYSpFwiaV/cKZrCvNI+4ENm1mtmFwBvA55099eA/2NmV1rQpfp14C/KlNWJ5heBmVkvwSKw\nfW2uU1T2ASPh8xEWfidlf49tqF/dwv+uPgc84+73FbyV+Daa2aq5GRZm1gfkgIOkoG0A7v4pd1/n\n7hcAHwL+0t1/nZS0z8yWm9mK8PmpwGbgCFG1L4YR4a0Eeelp4DXg6wXvfYpgUOAoMFRw/PKwUc8D\n97d7VLvB9l5FMCvjeeDWdtenyTZ8mWCV8kz4u7sG6AceBX4APAKsrPV77NQHwaySWYLZBwfDx5Y0\ntBG4BPhu2LbvAbeExxPftjJt3cTCLJpUtA+4IPzdHQKemoshUbVPC51ERFJKt+wTEUkpBXgRkZRS\ngBcRSSkFeBGRlFKAFxFJKQV4EZGUUoAXEUkpBXgRkZT6/6UvSkpq3U5AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1249622d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_labels, class_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for smoothing the CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 20\n",
    "h = np.ones(width)/float(width)\n",
    "smooth_cdfs = np.zeros_like(cdfs)\n",
    "for i in range(cdfs.shape[0]):\n",
    "    smoos = np.convolve(h,cdfs[i])\n",
    "    smoos = smoos[width/2:-(width/2 - 1)]\n",
    "    smoos[-(width/2):] = 1.\n",
    "    smooth_cdfs[i,:] = smoos\n",
    "\n",
    "smooth_cdfs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
